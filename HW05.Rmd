---
title: "HW05"
author: "Jackson Dial"
date: "4/6/2022"
output: word_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
dat1 <- read.table("../HW05Data/prob1.dat", header = TRUE)
dat2 <- read.table("../HW05Data/prob2.dat", header = TRUE)
```

# Question 1

__An automobile company wishes to study the effects of differences between drivers (factor A) and differences between cars (factor B) on gasoline consumption. Four drivers were selected at random; also five cars of the same model with manual transmission were randomly selected from the assembly line. Each driver drove each car twice over a 40 miles test course and miles per gallon were recorded.__

### Part A

__Suppose a two-way ANOVA model with an interaction term was ftt to address the study question. Should a fixed, random, or mixed effects model be fit? Justify your choice.__

A random model should be fitted, because both of the factors involved (driver and car) are random.

### Part B

__For the model you chose in part (a), write down the model equation and all associated assumptions. Describe each term in the model as they relate to the experimental scenario. How many parameters need to be estimated?__

$$
y_{ijk} = \mu_{..} + \alpha_i + \beta_i + (\alpha \beta)_{ij} + \epsilon_{ijk}
$$

$$
\alpha_i = \text{ The average deviation in response from the overall mean caused from car }i
$$

$$
\beta_j = \text{ The average deviation in response from the overall mean caused from driver }j
$$

A total of $1 + 3 + 4 + 12 = 20$ parameters need to be estimated. 

### Part C

__Test whether or not the two factors interact. State the hypotheses, form of the test statistic (i.e. numerator MS and denominator MS), p-value, and conclusion of the test.__

```{r}
fit1c <- aov(lm(mpg ~ (as.factor(driver) + as.factor(car))^2, data = dat1))
summary(fit1c)
```
The null hypothesis for this test is:

$$
H_o:\sigma_{\alpha\beta}^2 = 0
$$

$$
H_a:\sigma_{\alpha\beta}^2 > 0
$$

The form of the test statistic is as follows:

$$
\frac{MSAB}{MSE}
$$
The p-value for this test has been computed as $0.371$ meaning we fail to reject the null that the variance of the interaction term is equal to 0, so we should remove the interaction term from the model.

### Part D

__Test the main effects for each factor. State the hypotheses, form of the test statistic (i.e. numerator MS and denominator MS), p-value, and conclusion of the test.__


The null hypotheses and test statistics for these tests are:

$$
H_o:\sigma_{\alpha}^2 = 0
$$
$$
\frac{MSA}{MSAB}
$$


$$
H_o:\sigma_{\beta}^2 = 0
$$

$$
\frac{MSB}{MSAB}
$$

Since both of these p values are significant as shown in the output above, we reject the null hypotheses and can conclude that neither of the effects for these variables are equal to 0.

### Part E

__The owner of the automobile company is convinced that some drivers know how to handle larger vehicles better than others; as such, they will be able to get good gas mileage out any type of vehicle. Do your findings from part (c) and part (d) support this claim? Explain your reasoning.__

Yes, my findings do support this claim because the effect of the driver was concluded to be non-zero. This means that the driver does have a significant effect on the mpg of the car regardless of the effect of the car.

### Part F

__Provide point estimates of__ $\sigma^2_{\alpha}$ __and__ $\sigma^2_{\beta}$ __. Which factor appears to have the greater effect on gasoline consumption?__

```{r}
library(lmerTest)
mod1 <- lmer(mpg ~ (1|driver) + (1|car), data = dat1)
summary(mod1)

# for \sigma^2_{\alpha}
# (MSA - MSAB) / nb
# n = # of observations, b = levels of j (car)

# summary(aov(lm(mpg ~ (as.factor(driver) + as.factor(car))^2, dat1)))
# 
# 
# #These values are computed using the model that is including the interaction
# (93.43 - .2) / (40 * 5)
# # (MSB - MSAB) / na
# (23.68 - .2) / (40 * 4)


```

The driver appears to have a greater effect on mpg.

# Question 2

__In a pilot follow-up study, 159 subjects were randomly selected and asked whether they actually received a flu shot. The outcome variable y is coded 1 if subject received flu shot and 0 otherwise. The following predictors were collected: Age (continuous), health awareness index (continuous) which higher values indicating greater awareness, gender (1=male, 0=female).__

### Part A

__Find the maximum likelihood estimates beta0, beta1, beta2 and beta3. State the fitted logit model.__

```{r}
fit2a <- glm(formula = (y == 1) ~ age + health_index + as.factor(gender), data = dat2, family = "binomial")
summary(fit2a)
```

We will fit our values to the model below:

$$
\pi = f(x) = \frac{1}{1+ e^{-z}} \text{ where }z = \beta_0 + \beta_1Age + \beta_2Health + \beta_3Gender+ \epsilon
$$

Using the computed parameter estimates:

$$
\hat{\pi} = f(x) = \frac{1}{1+ e^{-\hat{z}}} \text{ where }z = -1.177 + (0.073*Age) + (-0.099*Health) + (0.434*Gender)
$$


### Part B

**NOT FINISHED**

__Estimate the adjusted odds ratio for each predictor in the model. Interpret these estimates. Test each of estimated odds ratio at 0.05 level of significance.__

```{r}
library(epiDisplay)
library(epitools)
library(oddsratio)

or_glm(data = dat2, model = fit2a)

```

### Part C

__What is the estimated probability that a male subject aged 55 yrs with health index of 60 will receive a flu shot__

```{r}
predict(fit2a, newdata = data.frame(gender = 1, age = 55, health_index = 60), type = "response")
```

The estimated probability that a male subject aged 55 with a health index of 60 will receive a flu shot is 6.42%.

### Part D

__Use the Wald test to determine whether gender can be dropped from the model in (a). State your conclusion and report the p-value__

$$
H_o: \beta_3 = 0
$$

$$
H_a: \beta_3 \neq 0
$$

```{r}
library(aod)
wald.test(Sigma = vcov(fit2a), b = coef(fit2a), Terms = 4)
```

Our wald test computes a p-value of 0.41, which is not significant, thus we fail to reject the null hypothesis. This means that gender can be dropped from the model.


### Part E

__Use the likelihood ratio test to determine whether gender can be dropped from the model in (a). State your conclusion and report the p-value. How your results differ from that you obtained in (d).__

```{r}
library(lmtest)
full_model <- glm(formula = (y == 1) ~ age + health_index + as.factor(gender), data = dat2, family = "binomial")
reduced_model <- glm(formula = (y == 1) ~ age + health_index, data = dat2, family = "binomial")

lrtest(full_model, reduced_model)
```

The computed p-value for this test is 0.402, meaning that the full model and the reduced model fit the data equally well. This is the same conclusion as in part d, that age can be removed from the model.

